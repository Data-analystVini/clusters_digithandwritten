# -*- coding: utf-8 -*-
"""Airpassengers_arimareg.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OEMCQVpe_gsxfAjhEeshQbQGCeSffTOb

**Pmdarima (originally pyramid-arima , for the anagram of 'py' + 'arima') is a statistical library designed to fill the void in Python's time series analysis capabilities. This includes: The equivalent of R's auto. arima functionality. A collection of statistical tests of stationarity and seasonality.**
"""

import numpy as np
import pandas as pd
from statsmodels.tsa.stattools import adfuller#The Augmented Dickey-Fuller test can be used to test for a unit root in a univariate process in the presence of serial correlation.
!pip install pmdarima
import pmdarima as pm

"""**adfuller() fn allows the user to specify the number of lags to include in the OLS regression by using the optional argument**"""

df=pd.read_csv('/content/drive/MyDrive/AirPassengers.csv')
print(df)
print(df.columns)

from datetime import datetime
import matplotlib.pyplot as plt

print(df.columns)

#string to date format
df['Month'] = pd.to_datetime(df['Month'],infer_datetime_format=True)
df = df.set_index(['Month'])
df.head(5)

"""**the visualization of the airline passenger's data, we can look for these components. At first glance, there looks to be a positive trend and some sort of seasonality or cyclicity in the dataset.**"""

plt.figure(figsize=(15,7))
plt.title("Number of Airline Passengers by Date")
plt.xlabel('Date')
plt.ylabel('Passengers')
plt.plot(df)
plt.show()

"""**ROLLING STATISTICS**

A rolling average is a great way to visualize how the dataset is trending. As the dataset provides counts by month, a window size of 12 will give us the annual rolling average.

We will also include the rolling standard deviation to see how much the data varies from the rolling average. **bold text**
"""

#Determine rolling statistics
df["rolling_avg"] = df["#Passengers"].rolling(window=12).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level
df["rolling_std"] = df["#Passengers"].rolling(window=12).std()

#Plot rolling statistics
plt.figure(figsize=(15,7))
plt.plot(df["#Passengers"], color='#379BDB', label='Original')
plt.plot(df["rolling_avg"], color='#D22A0D', label='Rolling Mean')
plt.plot(df["rolling_std"], color='#142039', label='Rolling Std')
plt.legend(loc='best')
plt.title('Rolling Mean & Standard Deviation')
plt.show(block=False)

"""**AUGMENTED DICKEY FULLER TEST**

The Augmented Dickey-Fuller Test is used to determine if time-series data is stationary or not. Similar to a t-test, we set a significance level before the test and make conclusions on the hypothesis based on the resulting p-value.

Null Hypothesis: The data is not stationary.

Alternative Hypothesis: The data is stationary.

For the data to be stationary (ie. reject the null hypothesis), the ADF test should have:

p-value <= significance level (0.01, 0.05, 0.10, etc.)
If the p-value is greater than the significance level then we can say that it is likely that the data is not stationary.

We can see in the ADF test below that the p-value is 0.991880, meaning that it is very likely that the data is not stationary.

**autolag='AIC': This argument specifies that the function should automatically determine the number of lags to use based on the Akaike Information Criterion (AIC), which helps in model selection.**
"""

#Augmented Dickeyâ€“Fuller test:
print('Results of Dickey Fuller Test:')
dftest = adfuller(df['#Passengers'], autolag='AIC')

dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
for key,value in dftest[4].items():
    dfoutput['Critical Value (%s)'%key] = value

print(dfoutput)

"""**ARIMA MODEL**"""

#Standard ARIMA Model
ARIMA_model = pm.auto_arima(df['#Passengers'],
                      start_p=1,
                      start_q=1,
                      test='adf', # use adftest to find optimal 'd'
                      max_p=3, max_q=3, # maximum p and q
                      m=1, # frequency of series (if m==1, seasonal is set to FALSE automatically)
                      d=None,# let model determine 'd'
                      seasonal=False, # No Seasonality for standard ARIMA
                      trace=False, #logs
                      error_action='warn', #shows errors ('ignore' silences these)
                      suppress_warnings=True,
                      stepwise=True)
print(ARIMA_model.summary())

"""Model Diagnostics

Four plots result from the plot_diagnostics function. The Standardized residual, Histogram plus KDE estimate, Normal q-q, and a correlogram.

We can interpret the model as a good fit based on the following conditions.

Standardized residual

There are no obvious patterns in the residuals, with values having a mean of zero and having a uniform variance.
Histogram plus KDE estimate

The KDE curve should be very similar to the normal distribution (labeled as N(0,1) in the plot)
Normal Q-Q

Most of the data points should lie on the straight line
Correlogram (ACF plot)

95% of correlations for lag greater than zero should not be significant. The grey area is the confidence band, and if values fall outside of this then they are statistically significant. In our case, there are a few values outside of this area, and therefore we may need to add more predictors to make the model more accurate **bold text**
"""

ARIMA_model.plot_diagnostics(figsize=(15,12))
plt.show()

"""**FORECASTING**

We can then use the model to forecast airline passenger counts over the next 24 months.

As we can see from the plot below, this doesn't seem to be a very accurate forecast. Maybe we need to change the model structure so that it takes into account seasonality? **bold text** **bold text**
"""

def forecast(ARIMA_model, periods=24):
    # Forecast
    n_periods = periods
    fitted, confint = ARIMA_model.predict(n_periods=n_periods, return_conf_int=True)
    index_of_fc = pd.date_range(df.index[-1] + pd.DateOffset(months=1), periods = n_periods, freq='MS')

    # make series for plotting purpose
    fitted_series = pd.Series(fitted, index=index_of_fc)
    lower_series = pd.Series(confint[:, 0], index=index_of_fc)
    upper_series = pd.Series(confint[:, 1], index=index_of_fc)

    # Plot
    plt.figure(figsize=(15,7))
    plt.plot(df["#Passengers"], color='#1f76b4')
    plt.plot(fitted_series, color='darkgreen')
    plt.fill_between(lower_series.index,
                    lower_series,
                    upper_series,
                    color='k', alpha=.15)

    plt.title("ARIMA - Forecast of Airline Passengers")
    plt.show()

forecast(ARIMA_model)

"""**SARIMA MODEL**"""

#Standard SARIMA Model
SARIMA_model = pm.auto_arima(df['#Passengers'],
                      start_p=1,
                      start_q=1,
                      test='adf', # use adftest to find optimal 'd'
                      max_p=3, max_q=3, # maximum p and q
                      m=12, # frequency of series (if m==1, seasonal is set to FALSE automatically)
                       start_P=0,
                      d=None,# let model determine 'd'
                      D=1,#order of the seasonal differencing
                      seasonal=True, #set to seasonal for SARIMA
                      trace=False, #logs
                      error_action='ignore', #shows errors ('ignore' silences these)
                      suppress_warnings=True,
                      stepwise=True)
print(SARIMA_model.summary())

"""**MODEL DIAGNOSTICS**

Standardized residual

The Standardized residual is much more consistent across the graph, meaning that the data is closer to being stationary.
Histogram plus KDE estimate

The KDE curve is similar to the normal distribution (not much changed here).
Normal Q-Q

The data points are clustered much closer to the line than in the ARIMA diagnostic plot.
Correlogram (ACF plot)

The grey area is the confidence band, and if values fall outside of this then they are statistically significant. We want all values inside this area. Adding the seasonality component did this! All the points now fall within the 95% confidence interval. **bold text**
"""

SARIMA_model.plot_diagnostics(figsize=(12,12))
plt.show()

"""**FORECASTING**

**It seems to be much more accurate than ARIMA Model**
"""

def forecast(SARIMA_model, periods=24):
    # Forecast
    n_periods = periods
    fitted, confint = SARIMA_model.predict(n_periods=n_periods, return_conf_int=True)
    index_of_fc = pd.date_range(df.index[-1] + pd.DateOffset(months=1), periods = n_periods, freq='MS')

    # make series for plotting purpose
    fitted_series = pd.Series(fitted, index=index_of_fc)
    lower_series = pd.Series(confint[:, 0], index=index_of_fc)
    upper_series = pd.Series(confint[:, 1], index=index_of_fc)

    # Plot
    plt.figure(figsize=(15,7))
    plt.plot(df["#Passengers"], color='#1f76b4')
    plt.plot(fitted_series, color='darkgreen')
    plt.fill_between(lower_series.index,
                    lower_series,
                    upper_series,
                    color='k', alpha=.15)

    plt.title("SARIMA - Forecast of Airline Passengers")
    plt.show()

forecast(SARIMA_model)